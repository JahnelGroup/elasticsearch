# Elasticsearch Filebeat Injestion with Logstash

**This docker-compose setup demonstrates how to injest Filebeat data into Elasticsearch with Logstash.**

## Getting Started

After pulling this repository you can start it as a background process with the **up -d** options. 

```bash
[elasticsearch-logstash-filebeat]$ docker-compose up -d
Creating network "elasticsearchlogstashfilebeat_default" with the default driver
Creating elasticsearchlogstashfilebeat_filebeat_1
Creating elasticsearchlogstashfilebeat_elasticsearch_1
Creating elasticsearchlogstashfilebeat_logs_1
Creating elasticsearchlogstashfilebeat_logstash_1
Creating elasticsearchlogstashfilebeat_kibana_1

[elasticsearch-logstash-filebeat]$ docker ps -a
CONTAINER ID        IMAGE                                                 COMMAND                  CREATED             STATUS                        PORTS                                            NAMES
b9b53afa3675        docker.elastic.co/kibana/kibana:5.6.3                 "/bin/sh -c /usr/l..."   6 seconds ago       Up 4 seconds                  0.0.0.0:5601->5601/tcp                           elasticsearchlogstashfilebeat_kibana_1
88dadf082454        docker.elastic.co/logstash/logstash:5.6.3             "/usr/local/bin/do..."   6 seconds ago       Up 4 seconds                  0.0.0.0:5044->5044/tcp, 9600/tcp                 elasticsearchlogstashfilebeat_logstash_1
9c39f21befce        docker.elastic.co/elasticsearch/elasticsearch:5.6.3   "/bin/bash bin/es-..."   7 seconds ago       Up 5 seconds                  0.0.0.0:9200->9200/tcp, 0.0.0.0:9300->9300/tcp   elasticsearchlogstashfilebeat_elasticsearch_1
7d6c81728f47        docker.elastic.co/beats/filebeat:5.6.3                "filebeat -e"            7 seconds ago       Restarting (1) 1 second ago                                                    elasticsearchlogstashfilebeat_filebeat_1
adbd9b36b80f        elasticsearchlogstashfilebeat_logs                    "sh /logs.sh"            7 seconds ago       Up 5 seconds                                                                   elasticsearchlogstashfilebeat_logs_1

[elasticsearch-logstash-filebeat]$ docker logs -f elasticsearchlogstashfilebeat_logs_1
{"timestamp":1510077380,"threadId":1,"thread":"main","level":"INFO","loggerName":"com.sample.Log","message":{"log_number":1,"log_msg":"Hello from log 1"}}
{"timestamp":1510077385,"threadId":1,"thread":"main","level":"INFO","loggerName":"com.sample.Log","message":{"log_number":2,"log_msg":"Hello from log 2"}}
{"timestamp":1510077390,"threadId":1,"thread":"main","level":"INFO","loggerName":"com.sample.Log","message":{"log_number":3,"log_msg":"Hello from log 3"}}
```

## How it works

This will stand up an ELK stack to process the logs generated by the [logs.sh](logs/logs.sh) sample program. The logs generated wil be in structued JSON format. The Filebeat agent will be watching the log file and send them to logstash to be parsed and indexed into Elasticsearch.

* Elasticsearch will be running at (http://localhost:9200)[http://localhost:9200] 
* Kibana will be at (http://localhost:5601)[http://localhost:5601]. 
* Logstash will be listening on 5044
* **Both will be protected with the default credentials: elastic / changeme**.

## Kibana Visualization

When loading Kibana for the first time you need to define an index. Since we did not define a custom index pattern
logstash will auto-generate one for us that Kibana will assume by default. When you load Kibana for the first time 
leave the index pattern alone and leave the default **@timestamp Time Filter field**. 